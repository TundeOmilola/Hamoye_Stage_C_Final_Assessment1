{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "Elect_dataset = pd.read_csv(r'C:\\Users\\tunde\\Desktop\\Hamoye Experience\\Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    6380\n",
       "stable      3620\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Elect_dataset['stabf'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Elect_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "Elect_dataset=Elect_dataset.drop(columns=['stab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     False\n",
       "tau2     False\n",
       "tau3     False\n",
       "tau4     False\n",
       "p1       False\n",
       "p2       False\n",
       "p3       False\n",
       "p4       False\n",
       "g1       False\n",
       "g2       False\n",
       "g3       False\n",
       "g4       False\n",
       "stabf    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Elect_dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    6380\n",
       "stable      3620\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.utils\n",
    "Elect_dataset = sklearn.utils.shuffle(Elect_dataset)\n",
    "Elect_dataset = Elect_dataset.reset_index(drop= True )\n",
    "Elect_dataset.shape\n",
    "Elect_dataset.stabf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Elect_dataset.drop(columns=['stabf'])\n",
    "y = Elect_dataset['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    5121\n",
       "stable      2879\n",
       "Name: stabf, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.2 , random_state= 1 )\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_balanced = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'gini', random_state = 1)\n",
    "classifier.fit(x_train_balanced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87771217, 0.87775593, 0.88615399, 0.85655297, 0.87595729])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(classifier, x_train_balanced, y_train, cv= 5 , scoring= 'f1_macro' )\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score,confusion_matrix\n",
    "cnf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[ 'stable' , 'unstable' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 644,   97],\n",
       "       [ 106, 1153]], dtype=int64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print( 'Accuracy: {}' .format(round(accuracy* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 92\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true=y_test, y_pred=y_pred, pos_label= 'unstable' )\n",
    "print( 'Precision: {}' .format(round(precision* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 92\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_true=y_test, y_pred=y_pred, pos_label= 'unstable' )\n",
    "print( 'Recall: {}' .format(round(recall* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 92\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, pos_label= 'unstable' )\n",
    "print( 'F1: {}' .format(round(f1* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extral Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'unstable', ..., 'stable', 'unstable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "classifier2 = ExtraTreesClassifier(random_state=1, n_estimators=500, criterion='gini', min_samples_split=2, min_samples_leaf=8,\n",
    "                                  max_features='log2')\n",
    "classifier2.fit(x_train_balanced,y_train)\n",
    "y_pred2 = classifier2.predict(x_test)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90121247, 0.88798254, 0.88595166, 0.87317692, 0.88769901])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(classifier2, x_train_balanced, y_train, cv= 5 , scoring= 'f1_macro' )\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 566,  175],\n",
       "       [  13, 1246]], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score,confusion_matrix\n",
    "cnf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred2, labels=[ 'stable' , 'unstable' ])\n",
    "cnf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred2)\n",
    "print( 'Accuracy: {}' .format(round(accuracy* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 88\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true=y_test, y_pred=y_pred2, pos_label= 'unstable' )\n",
    "print( 'Precision: {}' .format(round(precision* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 99\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_true=y_test, y_pred=y_pred2, pos_label= 'unstable' )\n",
    "print( 'Recall: {}' .format(round(recall* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 93\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true=y_test, y_pred=y_pred2, pos_label= 'unstable' )\n",
    "print( 'F1: {}' .format(round(f1* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost = XGBClassifier(random_state=1)\n",
    "xgb=xgboost.fit( x_train_balanced, y_train)\n",
    "y_pred3 = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unstable', 'unstable', 'unstable', ..., 'stable', 'unstable',\n",
       "       'unstable'], dtype=object)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91440661, 0.88546514, 0.90914572, 0.89481159, 0.90130047])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(xgb, x_train_balanced, y_train, cv= 5 , scoring= 'f1_macro' )\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 632,  109],\n",
       "       [  53, 1206]], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score,confusion_matrix\n",
    "cnf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred3, labels=[ 'stable' , 'unstable' ])\n",
    "cnf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred3)\n",
    "print( 'Accuracy: {}' .format(round(accuracy* 100 ), 4 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 92\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_true=y_test, y_pred=y_pred3, pos_label= 'unstable' )\n",
    "print( 'Precision: {}' .format(round(precision* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 96\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_true=y_test, y_pred=y_pred3, pos_label= 'unstable' )\n",
    "print( 'Recall: {}' .format(round(recall* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 93\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_true=y_test, y_pred=y_pred2, pos_label= 'unstable' )\n",
    "print( 'F1: {}' .format(round(f1* 100 ), 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y_trainlm = encoder.fit_transform(y_train)\n",
    "y_testlm = encoder.transform(y_test)\n",
    "y_testlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "train_data =lgb.Dataset(x_train_balanced,y_trainlm)\n",
    "params = {'learning_rate':0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightm= lgb.train(params, train_data, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 =lightm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65569111, 0.61830189, 0.63348743, ..., 0.59099051, 0.66978946,\n",
       "       0.60689636])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class sklearn.model_selection.RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(classifier2, distributions, random_state=1,scoring='accuracy', cv=5, verbose=1,n_jobs=-1, n_iter=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
